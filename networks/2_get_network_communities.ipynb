{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "secret-breast",
   "metadata": {},
   "source": [
    "# Get network communities\n",
    "\n",
    "This notebook gets network communities for the compendia (PAO1 and PA14) using different thresholds.\n",
    "\n",
    "The output of this notebook are files for each threshold. These files have the following columns:\n",
    "gene id | module id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "desperate-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering, AffinityPropagation\n",
    "from core_acc_modules import paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeec022a",
   "metadata": {},
   "source": [
    "## Set user parameters\n",
    "\n",
    "For now we will vary the correlation threshold (`corr_threshold`) but keep the other parameters consistent\n",
    "\n",
    "We will run this notebook for each threshold parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db4c4650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "corr_threshold = 0.5\n",
    "\n",
    "# Correlation matrix files\n",
    "pao1_corr_filename = os.path.join(\n",
    "    paths.LOCAL_DATA_DIR, f\"pao1_corr_{corr_threshold}.tsv\"\n",
    ")\n",
    "pa14_corr_filename = os.path.join(\n",
    "    paths.LOCAL_DATA_DIR, f\"pa14_corr_{corr_threshold}.tsv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO\n",
    "# Create variable to determine which clustering method to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stock-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load correlation data\n",
    "pao1_corr = pd.read_csv(pao1_corr_filename, sep=\"\\t\", index_col=0, header=0)\n",
    "pa14_corr = pd.read_csv(pa14_corr_filename, sep=\"\\t\", index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11f63a1",
   "metadata": {},
   "source": [
    "## Module detection\n",
    "To detect modules, we will use a clustering algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05e48b6",
   "metadata": {},
   "source": [
    "### DBSCAN\n",
    "[DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN):  Density-Based Spatial Clustering of Applications with Noise views clusters as areas of high density separated by areas of low density. The central component to the DBSCAN is the concept of _core samples_, which are samples that are in areas of high density. A cluster is therefore a set of _core samples_ that are close to each other (measured by some distance measure) and a set of non-core samples that are close to a core sample (but are not themselves core samples).\n",
    "\n",
    "A cluster is a set of core samples that can be built by recursively taking a core sample, finding all of its neighbors that are core samples, finding all of their neighbors that are core samples, and so on. A cluster also has a set of non-core samples, which are samples that are neighbors of a core sample in the cluster but are not themselves core samples. Intuitively, these samples are on the fringes of a cluster.\n",
    "\n",
    "* We define a core sample as being a sample in the dataset such that there exist `min_samples` other samples within a distance of `eps`, which are defined as neighbors of the core sample.\n",
    "* Using all default values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5174f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering using DBSCAN\n",
    "# pao1_clustering = DBSCAN().fit(pao1_corr)\n",
    "# pa14_clustering = DBSCAN().fit(pa14_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7507fe6",
   "metadata": {},
   "source": [
    "### Hierarchical clustering\n",
    "[Hierarchical clustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering): Initially, each object is assigned to its own cluster and then the algorithm proceeds iteratively, at each stage joining the two most similar clusters (i.e. linkage distance is minimized), continuing until there is just a single cluster.\n",
    "\n",
    "* n_cluster: The number of clusters to find.\n",
    "* linkage: Criterion used to determine distance between observations. 'average'=average distance of each observation in the two sets.\n",
    "\n",
    "* Note: It looks like this method tends to produce 1 very large cluster. To break this up we will iteratively apply hierarchal clustering on the largest cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b84cae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering using hierarchal clustering\n",
    "pao1_clustering = AgglomerativeClustering(\n",
    "    n_clusters=None, distance_threshold=0.5, linkage=\"average\"\n",
    ").fit(pao1_corr)\n",
    "pa14_clustering = AgglomerativeClustering(\n",
    "    n_clusters=None, distance_threshold=0.5, linkage=\"average\"\n",
    ").fit(pa14_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a98b0c9",
   "metadata": {},
   "source": [
    "### Affinity propogation\n",
    "\n",
    "[Affinity propogation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AffinityPropagation.html#sklearn.cluster.AffinityPropagation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de17761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering using affinity propogation\n",
    "# pao1_clustering = AffinityPropagation().fit(pao1_corr)\n",
    "# pa14_clustering = AffinityPropagation().fit(pa14_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f044bf1",
   "metadata": {},
   "source": [
    "## Membership assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad2f9c30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84      16\n",
       "41       5\n",
       "19       4\n",
       "3        3\n",
       "17       3\n",
       "13       3\n",
       "81       3\n",
       "35       2\n",
       "42       2\n",
       "83       2\n",
       "38       2\n",
       "7        2\n",
       "71       2\n",
       "37       2\n",
       "40       2\n",
       "82       2\n",
       "36       2\n",
       "150      2\n",
       "74       2\n",
       "18       2\n",
       "0        2\n",
       "8        2\n",
       "9        2\n",
       "1        2\n",
       "2        2\n",
       "20       2\n",
       "6        2\n",
       "4        2\n",
       "4675     1\n",
       "2656     1\n",
       "        ..\n",
       "3295     1\n",
       "5344     1\n",
       "1250     1\n",
       "3299     1\n",
       "5348     1\n",
       "1254     1\n",
       "3303     1\n",
       "5352     1\n",
       "1234     1\n",
       "3279     1\n",
       "1206     1\n",
       "1230     1\n",
       "3255     1\n",
       "5304     1\n",
       "1210     1\n",
       "3259     1\n",
       "5308     1\n",
       "1214     1\n",
       "3263     1\n",
       "5312     1\n",
       "1218     1\n",
       "3267     1\n",
       "5316     1\n",
       "1222     1\n",
       "3271     1\n",
       "5320     1\n",
       "1226     1\n",
       "3275     1\n",
       "5324     1\n",
       "2045     1\n",
       "Name: module id, Length: 5512, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get module membership for a single threshold\n",
    "# Format and save output to have columns: gene_id | group_id\n",
    "pao1_membership_df = pd.DataFrame(\n",
    "    data={\"module id\": pao1_clustering.labels_}, index=pao1_corr.index\n",
    ")\n",
    "\n",
    "pao1_membership_df[\"module id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa745bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181     6\n",
       "8       6\n",
       "15      5\n",
       "1       3\n",
       "10      3\n",
       "86      3\n",
       "0       2\n",
       "42      2\n",
       "7       2\n",
       "18      2\n",
       "40      2\n",
       "19      2\n",
       "90      2\n",
       "39      2\n",
       "3       2\n",
       "43      2\n",
       "81      2\n",
       "82      2\n",
       "80      2\n",
       "21      2\n",
       "44      2\n",
       "20      2\n",
       "4       2\n",
       "9       2\n",
       "6       2\n",
       "2       2\n",
       "16      2\n",
       "4719    1\n",
       "2704    1\n",
       "649     1\n",
       "       ..\n",
       "5424    1\n",
       "1330    1\n",
       "3379    1\n",
       "5428    1\n",
       "1334    1\n",
       "3383    1\n",
       "5432    1\n",
       "3359    1\n",
       "1310    1\n",
       "5404    1\n",
       "1294    1\n",
       "3331    1\n",
       "5380    1\n",
       "1286    1\n",
       "3335    1\n",
       "5384    1\n",
       "1290    1\n",
       "3339    1\n",
       "5388    1\n",
       "3343    1\n",
       "3355    1\n",
       "5392    1\n",
       "1298    1\n",
       "3347    1\n",
       "5396    1\n",
       "1302    1\n",
       "3351    1\n",
       "5400    1\n",
       "1306    1\n",
       "4096    1\n",
       "Name: module id, Length: 5850, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get module membership for a single threshold\n",
    "# Format and save output to have columns: gene_id | group_id\n",
    "pa14_membership_df = pd.DataFrame(\n",
    "    data={\"module id\": pa14_clustering.labels_}, index=pa14_corr.index\n",
    ")\n",
    "\n",
    "pa14_membership_df[\"module id\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5788844",
   "metadata": {},
   "source": [
    "**Final method:**\n",
    "We will use <Method> because ...\n",
    "\n",
    "    Thoughts on different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa8b8e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save membership dataframe\n",
    "# pao1_membership_df.to_csv(pao1_membership_filename, sep=\"\\t\")\n",
    "# pa14_membership_df.to_csv(pa14_membership_filename, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python [conda env:core_acc] *",
   "language": "python",
   "name": "conda-env-core_acc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
