{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "secret-breast",
   "metadata": {},
   "source": [
    "# Get network communities\n",
    "\n",
    "This notebook gets network communities for the compendia (PAO1 and PA14) using different thresholds.\n",
    "\n",
    "The output of this notebook are files for each threshold. These files have the following columns:\n",
    "gene id | module id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "desperate-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering, AffinityPropagation\n",
    "from core_acc_modules import paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeec022a",
   "metadata": {},
   "source": [
    "## Set user parameters\n",
    "\n",
    "For now we will vary the correlation threshold (`corr_threshold`) but keep the other parameters consistent\n",
    "\n",
    "We will run this notebook for each threshold parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db4c4650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User params to set\n",
    "\n",
    "# Clustering method\n",
    "# Choices: {\"dbscan\", \"hierarchal\", \"affinity\"}\n",
    "cluster_method = \"affinity\"\n",
    "\n",
    "# DBSCAN params\n",
    "density_threshold = 8\n",
    "\n",
    "# Hierarchical clustering params\n",
    "hier_threshold = 8\n",
    "link_dist = \"average\"\n",
    "\n",
    "# Affinity params\n",
    "affinity_damping = 0.6\n",
    "\n",
    "# Correlation matrix files\n",
    "pao1_corr_filename = paths.PAO1_CORR_LOG_SPELL\n",
    "pa14_corr_filename = paths.PA14_CORR_LOG_SPELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stock-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load correlation data\n",
    "pao1_corr = pd.read_csv(pao1_corr_filename, sep=\"\\t\", index_col=0, header=0)\n",
    "pa14_corr = pd.read_csv(pa14_corr_filename, sep=\"\\t\", index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11f63a1",
   "metadata": {},
   "source": [
    "## Module detection\n",
    "To detect modules, we will use a clustering algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05e48b6",
   "metadata": {},
   "source": [
    "### DBSCAN\n",
    "[DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN):  Density-Based Spatial Clustering of Applications with Noise views clusters as areas of high density separated by areas of low density. The central component to the DBSCAN is the concept of _core samples_, which are samples that are in areas of high density. A cluster is therefore a set of _core samples_ that are close to each other (measured by some distance measure) and a set of non-core samples that are close to a core sample (but are not themselves core samples).\n",
    "\n",
    "A cluster is a set of core samples that can be built by recursively taking a core sample, finding all of its neighbors that are core samples, finding all of their neighbors that are core samples, and so on. A cluster also has a set of non-core samples, which are samples that are neighbors of a core sample in the cluster but are not themselves core samples. Intuitively, these samples are on the fringes of a cluster.\n",
    "\n",
    "* We define a core sample as being a sample in the dataset such that there exist `min_samples` other samples within a distance of `eps`, which are defined as neighbors of the core sample.\n",
    "* Here we use `eps=8` based on the observations in the [prevous notebook](1_correlation_analysis.ipynb). In the previous notebook we plotted the distribution of pairwise distances (pdist) per gene and we selected 8 based on where the distribution curve drops off on the left side to mark how similar gene pairs are.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5174f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering using DBSCAN\n",
    "if cluster_method == \"dbscan\":\n",
    "    pao1_clustering = DBSCAN(eps=density_threshold).fit(pao1_corr)\n",
    "    pa14_clustering = DBSCAN(eps=density_threshold).fit(pa14_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7507fe6",
   "metadata": {},
   "source": [
    "### Hierarchical clustering\n",
    "[Hierarchical clustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering): Initially, each object is assigned to its own cluster and then the algorithm proceeds iteratively, at each stage joining the two most similar clusters (i.e. linkage distance is minimized), continuing until there is just a single cluster.\n",
    "\n",
    "* n_cluster: The number of clusters to find.\n",
    "* linkage: Criterion used to determine distance between observations. 'average'=average distance of each observation in the two sets.\n",
    "* distance_threshold: The linkage distance threshold above which, clusters will not be merged\n",
    "* Here we use `distance_threshold=8` based on the observations in the [prevous notebook](1_correlation_analysis.ipynb). In the previous notebook we plotted the distribution of pairwise distances (pdist) per gene and we selected 8 based on where the distribution curve drops off on the left side to mark how similar gene pairs are.\n",
    "\n",
    "* Note: It looks like this method tends to produce 1 very large cluster. To break this up we will iteratively apply hierarchal clustering on the largest cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b84cae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering using hierarchal clustering\n",
    "if cluster_method == \"hierarchal\":\n",
    "    pao1_clustering = AgglomerativeClustering(\n",
    "        n_clusters=None, distance_threshold=hier_threshold, linkage=link_dist\n",
    "    ).fit(pao1_corr)\n",
    "    pa14_clustering = AgglomerativeClustering(\n",
    "        n_clusters=None, distance_threshold=hier_threshold, linkage=link_dist\n",
    "    ).fit(pa14_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a98b0c9",
   "metadata": {},
   "source": [
    "### Affinity propogation\n",
    "\n",
    "[Affinity propogation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AffinityPropagation.html#sklearn.cluster.AffinityPropagation): creates clusters by sending messages between pairs of samples until convergence. The messages sent between points belong to one of two categories. The first is the responsibility $r(k,i)$, which is the accumulated evidence that sample $k$ should be the exemplar for sample $i$ compared to other exemplars. The second is the availability $a(k,i)$ which is the accumulated evidence that sample $i$ should choose sample $k$to be its exemplar. _Exemplar_ meaning the members of the input set that are representative of clusters -- similar to _centroids_ in k-means. Unlike k-means this method doesn't require a preset $k$ to be chosen.\n",
    "\n",
    "* damping: Damping factor (between 0.5 and 1) is the extent to which the current value is maintained relative to incoming values (weighted 1 - damping). This in order to avoid numerical oscillations when updating these values. Default is 0.5. Using default for PA14 data, the model didn't converge so we increased this to 0.6.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de17761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering using affinity propogation\n",
    "if cluster_method == \"affinity\":\n",
    "    pao1_clustering = AffinityPropagation(random_state=0).fit(pao1_corr)\n",
    "    pa14_clustering = AffinityPropagation(random_state=0, damping=affinity_damping).fit(\n",
    "        pa14_corr\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f044bf1",
   "metadata": {},
   "source": [
    "## Membership assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad2f9c30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "562    47\n",
       "304    35\n",
       "178    34\n",
       "72     34\n",
       "457    29\n",
       "62     27\n",
       "159    26\n",
       "547    26\n",
       "481    26\n",
       "9      25\n",
       "203    24\n",
       "503    24\n",
       "380    23\n",
       "230    23\n",
       "54     23\n",
       "415    22\n",
       "443    22\n",
       "317    21\n",
       "332    21\n",
       "188    21\n",
       "99     21\n",
       "337    20\n",
       "202    20\n",
       "183    19\n",
       "535    19\n",
       "522    19\n",
       "22     19\n",
       "379    18\n",
       "158    18\n",
       "421    18\n",
       "       ..\n",
       "311     5\n",
       "500     4\n",
       "520     4\n",
       "119     4\n",
       "475     4\n",
       "187     4\n",
       "48      4\n",
       "208     4\n",
       "524     4\n",
       "235     4\n",
       "189     4\n",
       "315     4\n",
       "217     4\n",
       "194     4\n",
       "518     4\n",
       "13      4\n",
       "348     4\n",
       "106     3\n",
       "282     3\n",
       "499     3\n",
       "521     3\n",
       "66      3\n",
       "38      3\n",
       "146     3\n",
       "483     3\n",
       "16      3\n",
       "358     3\n",
       "470     3\n",
       "122     2\n",
       "548     2\n",
       "Name: module id, Length: 564, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get module membership for a single threshold\n",
    "# Format and save output to have columns: gene_id | group_id\n",
    "pao1_membership_df = pd.DataFrame(\n",
    "    data={\"module id\": pao1_clustering.labels_}, index=pao1_corr.index\n",
    ")\n",
    "\n",
    "pao1_membership_df[\"module id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa745bfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265    39\n",
       "589    36\n",
       "524    36\n",
       "439    35\n",
       "353    33\n",
       "159    32\n",
       "580    29\n",
       "301    28\n",
       "410    28\n",
       "128    27\n",
       "506    27\n",
       "508    26\n",
       "255    26\n",
       "14     25\n",
       "387    24\n",
       "463    24\n",
       "571    24\n",
       "570    23\n",
       "94     23\n",
       "21     23\n",
       "434    23\n",
       "339    21\n",
       "354    21\n",
       "393    21\n",
       "264    21\n",
       "62     21\n",
       "91     20\n",
       "355    20\n",
       "490    20\n",
       "93     20\n",
       "       ..\n",
       "296     5\n",
       "35      4\n",
       "459     4\n",
       "477     4\n",
       "445     4\n",
       "24      4\n",
       "127     4\n",
       "579     4\n",
       "521     4\n",
       "518     4\n",
       "430     4\n",
       "555     4\n",
       "78      4\n",
       "29      4\n",
       "502     4\n",
       "7       4\n",
       "572     4\n",
       "252     4\n",
       "383     4\n",
       "488     4\n",
       "201     4\n",
       "480     4\n",
       "258     4\n",
       "163     3\n",
       "510     3\n",
       "563     3\n",
       "136     3\n",
       "560     3\n",
       "466     3\n",
       "531     3\n",
       "Name: module id, Length: 593, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get module membership for a single threshold\n",
    "# Format and save output to have columns: gene_id | group_id\n",
    "pa14_membership_df = pd.DataFrame(\n",
    "    data={\"module id\": pa14_clustering.labels_}, index=pa14_corr.index\n",
    ")\n",
    "\n",
    "pa14_membership_df[\"module id\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5788844",
   "metadata": {},
   "source": [
    "**Final method:**\n",
    "We will use <Method> because ...\n",
    "\n",
    "    Thoughts on different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa8b8e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save membership dataframe\n",
    "pao1_membership_filename = os.path.join(\n",
    "    paths.LOCAL_DATA_DIR, f\"pao1_modules_{cluster_method}.tsv\"\n",
    ")\n",
    "pa14_membership_filename = os.path.join(\n",
    "    paths.LOCAL_DATA_DIR, f\"pa14_modules_{cluster_method}.tsv\"\n",
    ")\n",
    "pao1_membership_df.to_csv(pao1_membership_filename, sep=\"\\t\")\n",
    "pa14_membership_df.to_csv(pa14_membership_filename, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python [conda env:core_acc] *",
   "language": "python",
   "name": "conda-env-core_acc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
