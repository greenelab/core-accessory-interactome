{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align and quantify samples\n",
    "\n",
    "The second step is to align our samples against our built index and quantify reads. This notebook aligns a pilot set of samples against the PAO1, PA14 and and PAO1 reference genomes. \n",
    "\n",
    "**Input:**\n",
    "* Index of reference transcriptome\n",
    "* FASTQ of experimental samples\n",
    "\n",
    "**Output:**\n",
    "* For each query (fragment), the reference sequences (transcripts), strand and position from which the query may have likely originated. In many cases, this mapping information is sufficient for downstream analysis like transcript quantification\n",
    "* Each sample will have a quantification file (called quant.sf). The TSV file will contain the name (Name) of each transcript, its length (Length), effective length (EffectiveLength), and its abundance in terms of Transcripts Per Million (TPM) and estimated number of reads (NumReads) originating from this transcript.\n",
    "  * The first two columns are self-explanatory, the name of the transcript and the length of the transcript in base pairs (bp).\n",
    "  * The effective length represents the various factors that effect the length of transcript (i.e degradation, technical limitations of the sequencing platform)\n",
    "  * Salmon outputs ‘pseudocounts’ which predict the relative abundance of different isoforms in the form of three possible metrics (KPKM, RPKM, and TPM). TPM (transcripts per million) is a commonly used normalization method as described in [1] and is computed based on the effective length of the transcript.\n",
    "  * Estimated number of reads (an estimate of the number of reads drawn from this transcript given the transcript’s relative abundance and length)\n",
    "\n",
    "**Algorithm:**\n",
    "* Given the index and a set of sequenced reads, the quant command quasi-maps the reads and uses the resulting mapping information to estimate transcript abundances.\n",
    "* Quasi-map is a way to map sequenced fragments (single or paired-end reads) to a target transcriptome. Quasi-mapping produces what we refer to as fragment mapping information. In particular, it provides, for each query (fragment), the reference sequences (transcripts), strand and position from which the query may have likely originated. In many cases, this mapping information is sufficient for downstream analysis like quantification.\n",
    "\n",
    "Basic steps:\n",
    "1. Scan read until k-mer appears in the hash table\n",
    "2. Look up all SA intervals (reference suffixes) containing that k-mer\n",
    "3. Maximum mappable prefix (MMP) finds the longest read sequence that exactly matches the reference suffix \n",
    "4. Determine the next informative position (NIP) by a k-mer skipping approach\n",
    "5. Repeat until the end of the read\n",
    "6. Reports all MMPs that read intersected with\n",
    "\n",
    "https://hbctraining.github.io/Intro-to-rnaseq-hpc-O2/lessons/08_salmon.html\n",
    "\n",
    "**Command:**\n",
    "\n",
    "Command and parameters:\n",
    "\n",
    "`> ./bin/salmon quant -i transcripts_index -l <LIBTYPE> -1 reads1.fq -2 reads2.fq --validateMappings -o transcripts_quant`\n",
    "\n",
    "* libtype = Determines how the reads should be interpreted including the relative orientation of paired ends (inward, outward, matching) and strandedness (stranded=specify if read1 comes from forward or reverse strand, unstranded). Currently using “A” which lets Salmon automatically decide\n",
    "  * https://salmon.readthedocs.io/en/latest/salmon.html\n",
    "  * (pg 38) https://buildmedia.readthedocs.org/media/pdf/salmon/stable/salmon.pdf\n",
    "* What does strand bias in output mean? Strand_bias is such that a value of 0.5 means there is no bias (i.e. half of the fragments start with read 1 on the forward strand and half start with read 1 on the reverse complement strand). \n",
    "  * Based on lib_format_counts.json file, the bias is very close to 0.5, just above\n",
    "  * https://hbctraining.github.io/Intro-to-rnaseq-hpc-O2/lessons/08_salmon.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from core_acc_modules import paths\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download SRA data\n",
    "\n",
    "Note: Need to delete `sra` folder between runs otherwise `fastq-dump` will be called on all files in `sra` folder which can include more than your sra accessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(paths.SRA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-01-14T17:07:07 prefetch.2.8.2: 1) Downloading 'SRR13160334'...\n",
      "2021-01-14T17:07:07 prefetch.2.8.2:  Downloading via https...\n",
      "2021-01-14T17:11:26 prefetch.2.8.2: 1) 'SRR13160334' was downloaded successfully\n",
      "2021-01-14T17:11:27 prefetch.2.8.2: 'SRR13160334' has 0 unresolved dependencies\n",
      "\n",
      "2021-01-14T17:11:27 prefetch.2.8.2: 2) Downloading 'ERR3642743'...\n",
      "2021-01-14T17:11:27 prefetch.2.8.2:  Downloading via https...\n",
      "2021-01-14T17:18:39 prefetch.2.8.2: 2) 'ERR3642743' was downloaded successfully\n",
      "2021-01-14T17:18:39 prefetch.2.8.2: 'ERR3642743' has 0 unresolved dependencies\n",
      "\n",
      "2021-01-14T17:18:41 prefetch.2.8.2: 3) Downloading 'SRR13234437'...\n",
      "2021-01-14T17:18:41 prefetch.2.8.2:  Downloading via https...\n",
      "2021-01-14T17:32:22 prefetch.2.8.2 sys: libs/kns/unix/syssock.c:606:KSocketTimedRead: timeout exhausted while reading file within network system module - mbedtls_ssl_read returned -76 ( NET - Reading information from the socket failed )\n",
      "2021-01-14T17:32:22 prefetch.2.8.2 int: libs/kns/unix/syssock.c:606:KSocketTimedRead: timeout exhausted while reading file within network system module - H\n",
      "2021-01-14T17:32:22 prefetch.2.8.2: 3) failed to download SRR13234437\n"
     ]
    }
   ],
   "source": [
    "# Download sra data files\n",
    "! prefetch --option-file $paths.SRA_ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get FASTQ files associated with SRA downloads\n",
    "\n",
    "The fastq files store the RNA-seq results, including: sequencing and quality scores for each base call.\n",
    "\n",
    "Here is a nice blog to explain how to read fastq files: https://thesequencingcenter.com/knowledge-base/fastq-files/\n",
    "\n",
    "The fastq files gives the sequence of a read at a given location. Our goal is to map these reads to a reference genome so that we can quantify the number of reads that are at a given location, to determine the level of expression.\n",
    "\n",
    "**Note:**\n",
    "Before using `fasterq-dump` you need to configure it: https://github.com/ncbi/sra-tools/wiki/03.-Quick-Toolkit-Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(paths.FASTQ_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This sra toolkit installation has not been configured.\n",
      "Before continuing, please run: vdb-config --interactive\n",
      "For more information, see https://www.ncbi.nlm.nih.gov/sra/docs/sra-cloud/\n",
      "This sra toolkit installation has not been configured.\n",
      "Before continuing, please run: vdb-config --interactive\n",
      "For more information, see https://www.ncbi.nlm.nih.gov/sra/docs/sra-cloud/\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'for f in $1/*;\\ndo\\n    fasterq-dump $f -O $paths.FASTQ_DIR/ -f\\ndone\\n'' returned non-zero exit status 78.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cad1f48e2e87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-s $paths.SRA_DIR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'for f in $1/*;\\ndo\\n    fasterq-dump $f -O $paths.FASTQ_DIR/ -f\\ndone\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/core_acc/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2380\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2381\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2382\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/core_acc/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/core_acc/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/core_acc/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'for f in $1/*;\\ndo\\n    fasterq-dump $f -O $paths.FASTQ_DIR/ -f\\ndone\\n'' returned non-zero exit status 78."
     ]
    }
   ],
   "source": [
    "%%bash -s $paths.SRA_DIR\n",
    "for f in $1/*;\n",
    "do\n",
    "    fasterq-dump $f -O $paths.FASTQ_DIR/ -f\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify gene expression\n",
    "Now that we have our index built and all of our data downloaded, we’re ready to quantify our samples\n",
    "\n",
    "**For each sample we have read counts per gene (where the genes are based on the reference gene file provided above).** \n",
    "\n",
    "Note about TPM calculation:\n",
    "* For sample A, transcript X will have read count\n",
    "* Reads per kilobase (RPK) = read count/length of the transcript\n",
    "* Per million scaling factor = sum(read count/length across all samples for that transcript)/1M\n",
    "* TPM = RPK/per million scaling factor\n",
    "* TPM will depend on the scaling factor. If the number of mapped reads is very low then scale factor will be very low and so any trancript that mapped will be increased to create outliers since we’re dividing by a small scale factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get quants using PAO1 reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(paths.PAO1_QUANT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s $paths.PAO1_QUANT $paths.FASTQ_DIR $paths.PAO1_INDEX\n",
    "\n",
    "for FILE_PATH in $2/*;\n",
    "do\n",
    "\n",
    "# get file name\n",
    "sample_name=`basename ${FILE_PATH}`\n",
    "\n",
    "# remove extension from file name\n",
    "sample_name=\"${sample_name%_*}\"\n",
    "\n",
    "# get base path\n",
    "base_name=${FILE_PATH%/*}\n",
    "\n",
    "echo \"Processing sample ${sample_name}\"\n",
    "\n",
    "salmon quant -i $3 \\\n",
    "             -l A \\\n",
    "             -r ${base_name}/${sample_name}/* \\\n",
    "             -o $1/${sample_name}_quant\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get quants using PA14 reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(paths.PA14_QUANT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s $paths.PA14_QUANT $paths.FASTQ_DIR $paths.PA14_INDEX\n",
    "\n",
    "for FILE_PATH in $2/*;\n",
    "do\n",
    "\n",
    "# get file name\n",
    "sample_name=`basename ${FILE_PATH}`\n",
    "\n",
    "# remove extension from file name\n",
    "sample_name=\"${sample_name%_*}\"\n",
    "\n",
    "# get base path\n",
    "base_name=${FILE_PATH%/*}\n",
    "\n",
    "echo \"Processing sample ${sample_name}\"\n",
    "\n",
    "salmon quant -i $3 -l A \\\n",
    "            -1 ${base_name}/${sample_name}_1.fastq \\\n",
    "            -2 ${base_name}/${sample_name}_2.fastq \\\n",
    "            -p 8 --validateMappings -o $1/${sample_name}_quant\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get quants using phage reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(paths.PHAGE_QUANT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash -s $paths.PHAGE_QUANT $paths.FASTQ_DIR $paths.PHAGE_INDEX\n",
    "\n",
    "for FILE_PATH in $2/*;\n",
    "do\n",
    "\n",
    "# get file name\n",
    "sample_name=`basename ${FILE_PATH}`\n",
    "\n",
    "# remove extension from file name\n",
    "sample_name=\"${sample_name%_*}\"\n",
    "\n",
    "# get base path\n",
    "base_name=${FILE_PATH%/*}\n",
    "\n",
    "echo \"Processing sample ${sample_name}\"\n",
    "\n",
    "salmon quant -i $3 -l A \\\n",
    "            -1 ${base_name}/${sample_name}_1.fastq \\\n",
    "            -2 ${base_name}/${sample_name}_2.fastq \\\n",
    "            -p 8 --validateMappings -o $1/${sample_name}_quant\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate sample quantification to gene expression dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read through all sample subdirectories in quant/\n",
    "# Within each sample subdirectory, get quant.sf file\n",
    "data_dir = paths.PAO1_QUANT\n",
    "\n",
    "expression_pao1_df = pd.DataFrame(\n",
    "    pd.read_csv(file, sep=\"\\t\", index_col=0)[\"TPM\"].\n",
    "    rename(file.parent.name.split(\"_\")[0]) \n",
    "    for file in data_dir.rglob(\"*/quant.sf\"))    \n",
    "\n",
    "expression_pao1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read through all sample subdirectories in quant/\n",
    "# Within each sample subdirectory, get quant.sf file\n",
    "data_dir = paths.PA14_QUANT\n",
    "\n",
    "expression_pa14_df = pd.DataFrame(\n",
    "    pd.read_csv(file, sep=\"\\t\", index_col=0)[\"TPM\"].\n",
    "    rename(file.parent.name.split(\"_\")[0]) \n",
    "    for file in data_dir.rglob(\"*/quant.sf\"))    \n",
    "\n",
    "expression_pa14_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read through all sample subdirectories in quant/\n",
    "# Within each sample subdirectory, get quant.sf file\n",
    "data_dir = paths.PHAGE_QUANT\n",
    "\n",
    "expression_phage_df = pd.DataFrame(\n",
    "    pd.read_csv(file, sep=\"\\t\", index_col=0)[\"TPM\"].\n",
    "    rename(file.parent.name.split(\"_\")[0]) \n",
    "    for file in data_dir.rglob(\"*/quant.sf\"))    \n",
    "\n",
    "expression_phage_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save gene expression data\n",
    "expression_pao1_df.to_csv(paths.PAO1_GE, sep='\\t')\n",
    "expression_pa14_df.to_csv(paths.PA14_GE, sep='\\t')\n",
    "expression_phage_df.to_csv(paths.PHAGE_GE, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:core_acc] *",
   "language": "python",
   "name": "conda-env-core_acc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
